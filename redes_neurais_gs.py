# -*- coding: utf-8 -*-
"""Redes-Neurais-GS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ENRdbir21avioeH2FBAqtr0SY97dI3Xj

# 1- Título e Introdução

Criar uma Rede Neural capaz de prever o risco de ocorrência de enchentes em áreas urbanas, usando os dados de entrada mencionados. A entrega final deverá ser feita através do Google Colab.

# 2- Importação de bibliotecas
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

"""# 3- Descrição das bibliotecas

- **pandas / numpy**: manipulação e análise de dados tabulares.
- **matplotlib / seaborn**: visualização de dados e gráficos exploratórios.
- **sklearn**: ferramentas de machine learning como pré-processamento, divisão de dados e métricas.
- **tensorflow / keras**: construção, treinamento e avaliação da rede neural.

# 4- Carregamento e Exploração do Dataset
"""

df = pd.read_csv('/content/flood_risk_dataset_india.csv')

df.head()
df.info()
df.describe()
df.tail()
df.select_dtypes(include=['object']).columns

df

"""# 5- Análise Exploratória dos Dados

- O dataset contém informações sobre enchentes como nível da água, chuva acumulada, umidade, etc.
- Algumas colunas podem precisar de encoding, como a "Land Cover" e "Soil".
- Não há muitos valores ausentes, o que facilita o processamento.
- A variável target indica se houve enchente.

# 6- Pré-processamento dos Dados
"""

# Verificando se há duplicatas
duplicatas = df.duplicated()
duplicatas.sum()

#Verificando se há valores nulos
df.isnull().sum()

#Verificando se há informações fora do comum, como outliers e afins.

print("Umidade fora do intervalo [0, 100]:")
print(df[(df['Humidity (%)'] < 0) | (df['Humidity (%)'] > 100)])

print("Temperaturas fora da faixa [-30, 60]:")
print(df[(df['Temperature (°C)'] < -30) | (df['Temperature (°C)'] > 60)])

print("Rainfall negativa:")
print(df[df['Rainfall (mm)'] < 0])

print("River Discharge negativo:")
print(df[df['River Discharge (m³/s)'] < 0])

print("Water Level muito extremo:")
print(df[(df['Water Level (m)'] < -5) | (df['Water Level (m)'] > 50)])

print("Altitude muito fora do normal:")
print(df[(df['Elevation (m)'] < -500) | (df['Elevation (m)'] > 9000)])

print("Densidade populacional negativa:")
print(df[df['Population Density'] < 0])

#Aplicando One-Hot Encoding nas variáveis categóricas não-ordinais.
df = pd.get_dummies(df, columns=['Land Cover', 'Soil Type'], drop_first=False, dtype=int)

# Tirando a variável target do DataFrame, normalizando os dados e separando os conjuntos de dados de teste e treinamento
X, y = df.drop(columns=['Flood Occurred']), df['Flood Occurred']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# 7- Explicação do Pré-processamento

Durante o pré-processamento, verificamos a presença de duplicatas, valores nulos e outliers, além de aplicar One-Hot Encoding nas variáveis categóricas. Em seguida, dividimos o conjunto de dados em 80% para treinamento e 20% para teste. Nenhuma anomalia relevante foi identificada durante essa etapa, indicando que os dados estavam em boas condições para o uso no modelo

# 8- Construção do Modelo de Rede Neural
"""

#Arquitetura do modelo
model = tf.keras.Sequential(
  [
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(5, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
  ]
)

model.compile(
  optimizer = 'adam',
  loss= "binary_crossentropy",
  metrics=['accuracy', 'precision', 'recall', 'auc']
)

"""# 9- Explicação da Arquitetura do Modelo

A arquitetura do modelo foi escolhida baseada em testes, utilizando algumas técnicas como o dropout para desligamento de neurônios visando aumentar o aprendizado e acurácia do modelo. Utilizamos a função de ativação Sigmoid na última camada por se tratar de uma classificação binária (0 ou 1). Pelo mesmo motivo, usamos a função de binary_crossentropy para o loss. As métricas utilizadas são as sugeridas no documento.

# 10- Treinamento do Modelo
"""

training = model.fit(X_train_scaled, y_train, epochs= 25, validation_data =(X_test_scaled, y_test))

metrics_names = model.metrics_names
results = model.evaluate(X_test_scaled, y_test, verbose=0)

for name, value in zip(metrics_names, results):
    print(f"{name}: {value:.4f}")

"""# 11- Análise do Treinamento

Analisando os resultados obtidos pelo modelo, percebemos que o modelo não tem um bom aprendizado levando em consideração a acurácia... O loss do modelo também está muito alto, o que significa que o modelo não está tendo um aprendizado eficiente.

# 12 - Avaliação e Validação
"""

plt.plot(training.history['accuracy'], label='Acurácia')
plt.plot(training.history['precision'], label='Precisão')
plt.plot(training.history['recall'], label='Recall')
plt.plot(training.history['auc'], label='AUC')
plt.plot(training.history['val_accuracy'], label='Validação')
plt.title('Acurácia por Época')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.legend()
plt.grid(True)
plt.show()

"""# 13 - Discussão dos Resultados

Os resultados não foram satisfatórios, o modelo não aprende bem mesmo com algumas alterações feitas e testadas. Todas as métricas estão ruins ou medianas. Acreditamos que o problema esteja com os dados (features), que não são suficientes para determinar se houve ou não enchentes (variável target). Obtivemos overfitting e muitos problemas de generalização.

Uma melhoria futura seria fazer feature engineering, para melhorarmos a relação das features com o target, tornando assim, dados mais eficientes para o aprendizado da rede neural. Algo como combinarmos duas features existentes para criar uma nova, por exemplo. Outra opção seria utilizarmos outro modelo pra aprendizado, como sugestão teria o Random Forest.

# 14 - Conclusões e Próximos Passos

Foi desenvolvido uma Rede Neural MLP (Feed Forward) que tem como objetivo prever enchentes. Durante a arquitetura do modelo fizemos diversos testes para acharmos os melhores hiper-parâmetros, funções, quantidades de neurônios e técnicas de dropout. Ainda assim, não obtivemos um resultado satisfatório, embora tenhamos tentado diversas arquiteturas. Fizemos Análise de Correlação, PCA, Matriz de Confusão, Predição Binária e afins, e nessa análise, identificamos que de fato, os dados não são de boa qualidade para o modelo.

Os próximos passos seriam melhoramos a qualidade dos dados através de estratégias como o feature engineering, usarmos transfer learning com modelos pré-treinados, e gerarmos mais dados sintéticos.

Abaixo, segue algumas explorações que foram desenvolvidas:
"""

#Análise de correlação
correlation = df.corr(numeric_only=True)["Flood Occurred"].sort_values(ascending=False)
sns.barplot(x=correlation.values, y=correlation.index)
plt.title("Correlação com Flood Occurred")

# Predição binária
y_pred_prob = model.predict(X_test_scaled)
y_pred = (y_pred_prob > 0.5).astype(int)

# Matriz de confusão
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title("Matriz de Confusão")
plt.show()

# Relatório de Classificação
print("Relatório de Classificação:")
print(classification_report(y_test, y_pred))